\chapter{IOPs for Zero-Knowledge Polynomial Commitment}

In this chapter, we describe a simple method to add the zero-knowledge property to a given polynomial commitment scheme. This method uses random numbers to hide the actual coefficients and it works similarly to one-time pad encryption.

The idea behind this protocol is similar to \cite{orion}. But we generalize it to higher dimensions and we have different restrictions on query patterns. Also, \cite{orion} uses a code-switching technique to further improve efficiency. We execute the protocol in the previous chapter twice, once for the coefficient matrix and once for the pad matrix. The protocol executed for the pad matrix will terminate early to prevent information leaking. \cite{orion} does not has this concern because of their more restricted query pattern.

We first present the construction, then we prove the construction is complete and sound. For the zero-knowledge property, we first present a failed attempt of proof, then we fix it and present the complete proof.

\section{Proximity Test}

In this section, we describe the testing phase in the above protocol formally in terms of an IOPP (interactive oracle proof of proximity) with point queries for the relation $R_\otimes^1(\mathbb{F}, C, m, N, t)$ between a prover $\textbf{P}$ and a verifier $\textbf{V}$.

The prover $\textbf{P}$ takes as input an instance $\mathbb{X} = (\mathbb{F}, C, m, N, t)$ and witness $\mathbb{W} = (M_0^{\prime}, M_1^{\prime}, \cdots, M_{t-1}^{\prime}, PAD_0^{\prime}, PAD_1^{\prime}, \cdots, PAD_{t-1}^{\prime})$. The verifier $\textbf{V}$ takes as input the instance $\mathbb{X}$.

\begin{enumerate}
    \item \textit{Interactive phase}. 
    
    In the beginning, $\textbf{P}$ sends the proof message $M_0^{\prime}$ and $PAD_0^{\prime}$ computed as:
$$
    M_0 = u \in \mathbb{F}^{m^t}
$$
$$
    M_0^{\prime} = \textbf{Enc}_{1,\cdots,t-1}(M_0 \oplus PAD_0) \in \mathbb{F}^{N^{t-1} \cdot m}
$$
$$
    PAD_0^{\prime} = \textbf{Enc}_{1,\cdots,t-1}(PAD_0) \in \mathbb{F}^{N^{t-1} \cdot m}
$$
    Note that $PAD_0$ is a matrix with a dimension identical to $M_0$ filled with random elements from $\mathbb{F}$. And $\oplus$ denotes elements-wise matrix addition.
    
    For each round $i \in [t-1]$:
    \begin{itemize}
        \item $\textbf{V}$ sends random challenge message $r_i \in \mathbb{F}^m$.
        \item $\textbf{P}$ sends the proof message $M_i^{\prime}$ computed as:
$$
    PAD_i = \textbf{Fold}_{t-i+1}(PAD_{i-1}, r_i) \in \mathbb{F}^{m^{t-i}}
$$
$$
    M_i = \textbf{Fold}_{t-i+1}(M_{i-1}, r_i) \in \mathbb{F}^{m^{t-i}}
$$
$$
    M_i^\prime =  \textbf{Enc}_{1, \cdots, t- i - 1}(M_i \oplus PAD_I) \in \mathbb{F}^{N^{t-i-1} \cdot m}
$$
$$
    PAD_i^\prime =  \textbf{Enc}_{1, \cdots, t- i - 1}(PAD_i) \in \mathbb{F}^{N^{t-i-1} \cdot m}
$$

    \end{itemize}
    \item \textit{Query phase}. 
    
    In step 1, the verifier $\textbf{V}$ samples $l_1$ tuples of the form $(j_1, \cdots, j_t)$ in space $[N]^t$. Denote this set of tuples as $L_1$.
    The verifier $\textbf{V}$ proceeds as follows for each sampled tuple.
    
    For each $0 \le i \le t-1$, 
    the verifier $\textbf{V}$ will query $M_{i}^{\prime}$ at $(j_1, \cdots, j_{t-i-1}, j_k)$ for each $j_k \in [m]$. 
    
    Then the verifier $\textbf{V}$ will check the following equation for $i \in [t-1]$:
\begin{equation}
\label{eq:szkpctc_eq}
    \text{Enc}_{t-i}(M_i^\prime)[i_1, \cdots, i_{t-i}] \stackrel{?}{=} \textbf{Fold}_{t-i+1}(M_{i-1}^\prime, r_i) [i_1, \cdots, i_{t-i}]
\end{equation}

    In step 2, the verifier $\textbf{V}$ samples $l_2$ tuples of the form $(j_1^\prime, \cdots, j_t^\prime)$ in space $[N]^t$ with the restriction that $j_k^\prime \neq j_k$ for $\forall (j_1, j_2, \cdots, j_t) \in L_1$. Denote this set of tuples as $L_2$.
    The verifier $\textbf{V}$ proceeds as follows for each sampled tuple.
    
    For each $0 \le i \le t-1$, 
    the verifier $\textbf{V}$ will query $PAD_{i}^{\prime}$ at $(j_1^\prime, \cdots, j_{t-i-1}^\prime, j_k^\prime)$ for each $j_k^\prime \in [m]$. 
    
    Then the verifier $\textbf{V}$ will check the following equation for $i \in [t-2]$:
\begin{equation}
\label{eq:szkpctc_eq2}
    \text{Enc}_{t-i}(PAD_i^\prime)[i_1, \cdots, i_{t-i}] \stackrel{?}{=} \textbf{Fold}_{t-i+1}(PAD_{i-1}^\prime, r_i) [i_1, \cdots, i_{t-i}]
\end{equation}




\end{enumerate}

\section{Proximity Test Completeness}

\begin{lemma}
\label{lemma:szkpctcc}

IOPP = ($\textbf{P}$, $\textbf{V}$) has \textbf{perfect completeness}.

\end{lemma}
\begin{proof}
We begin by noting that the queries made by $\textbf{V}$ suffice to perform the checks in the query phase (see equation \ref{eq:szkpctc_eq} and \ref{eq:szkpctc_eq2}).

Next, observe that the verifier $\textbf{V}$ checks the following equation:
$$
    \text{Enc}_{t-i}(M_i^\prime) \stackrel{?}{=} 
    \textbf{Fold}_{t-i+1}(M_{i-1}^\prime, r_i) 
$$
Note that the left side of this equation is equivalent to:
\begin{align}
\text{Enc}_{t-i}(M_i^\prime) \nonumber
&= \text{Enc}_{t-i}(\textbf{Enc}_{1, \cdots, t- i - 1}(M_i \oplus PAD_i)) \nonumber \\
&= \textbf{Enc}_{1, \cdots, t-i}(M_i \oplus PAD_i) \nonumber \\
&= \textbf{Enc}_{1, \cdots, t-i}(\textbf{Fold}_{t-i+1}(M_{i-1} \oplus PAD_{i-1}, r_i)) \label{lb:exp1} \\
\end{align}
And the right side of this equation is equivalent to:
\begin{align}
\textbf{Fold}_{t-i+1}(M_{i-1}^\prime, r_i) 
&= \textbf{Fold}_{t-i+1}(\textbf{Enc}_{1, \cdots, t- i}(M_{i-1} \oplus PAD_{i-1}), r_i) \label{lb:exp2} \\
\end{align}
Since both \textbf{Fold} and \textbf{Enc} operations are linear operations, expression \ref{lb:exp1} and  expression \ref{lb:exp2} are equivalent to each other. And the similar argument is applied to the equation \ref{eq:szkpctc_eq2}.
The equations checked by the verifier $\textbf{V}$ hold.

\end{proof}




\section{Proximity Test Soundness}

\begin{lemma}
\label{lemma:szkpctc-soundness}


IOPP = ($\textbf{P}$, $\textbf{V}$) has soundness error at most:
$$
    \epsilon_{\text{ZK}}(\Delta_\otimes, t, l_1, l_2) = \epsilon(\Delta_\otimes, t, l_1) + \frac{\epsilon(\Delta_\otimes, t, l_2)}{\epsilon(\Delta_\otimes, 2, l_2)}
$$

\end{lemma}
\begin{proof}


This protocol performs two proximity tests in parallel. One on $M_i^\prime$ tensor and the other on $PAD_i$ tensor. The soundness error would be the sum of the soundness error introduced by the first proximity test and the second proximity test.


Formally speaking, suppose 
$$
    ((\mathbb{F}, C, m, N, t), (M_0^{\prime}, M_1^{\prime}, \cdots, M_{t-1}^{\prime}, PAD_0^{\prime}, PAD_1^{\prime}, \cdots, PAD_{t-1}^{\prime}))
$$ 
is not in relation $R_\otimes$. Then either $((\mathbb{F}, C, m, N, t), (M_0^{\prime}, M_1^{\prime}, \cdots, M_{t-1}^{\prime}))$ is not in relation $R_\otimes$, 
or $((\mathbb{F}, C, m, N, t), (PAD_0^{\prime}, PAD_1^{\prime}, \cdots, PAD_{t-1}^{\prime}))$ is not in relation $R_\otimes$.

If $((\mathbb{F}, C, m, N, t), (M_0^{\prime}, M_1^{\prime}, \cdots, M_{t-1}^{\prime}))$ is not in relation $R_\otimes$, then, the soundness error introduced by this part is $\epsilon(\Delta_\otimes, t, l_1)$. 

If $((\mathbb{F}, C, m, N, t), (PAD_0^{\prime}, PAD_1^{\prime}, \cdots, PAD_{t-1}^{\prime}))$ is not in relation $R_\otimes$, then, the soundness error introduced by this part is $\frac{\epsilon(\Delta_\otimes, t, l_2)}{\epsilon(\Delta_\otimes, 2, l_2)}$.

In a complete proximity test, we use $E_{last}$ to denote the event that the last round of the test is passed. And we use $E_{other}$ to denote the event that all other tests are passed.
The soundness error is the probability the verifier is convinced by a malicious input.
The soundness error of a complete proximity test is $P_t = \epsilon(\Delta_\otimes, t, l_2)$. And it is also the probability where both event $E_{last}$ and event $E_{other}$ occur. Therefore, $P_t = P_{E_{last}} \cdot P_{E_{last}}$. Note that $P_{E_{last}}$ is actually the soundness error when $t=2$, namely, $P_{E_{last}} = \epsilon(\Delta_\otimes, 2, l_2)$. And $P_{E_{other}}$ is the soundness error introduced by the second proximity test here, where the input is malicious and all tests except the last one are passed. Therefore, $P_{E_{other}} = \frac{P_{t}}{P_{E_{last}}} = \frac{\epsilon(\Delta_\otimes, t, l_2)}{\epsilon(\Delta_\otimes, 2, l_2)}$.

\end{proof}


\section{Proximity Test Zero-Knowledge}

\begin{lemma}
\label{lemma:szkpc-zk}

IOPP = ($\textbf{P}$, $\textbf{V}$) is \textbf{``almost'' semi-honest zero-knowledge}.

\end{lemma}
\begin{proof}

For every $(\mathbb{X}, \mathbb{W}) \in R_\otimes$ and choice of verifier randomness $\rho$, we can construct the polynomial-time simulator algorithm $\textbf{S}$ as follows:


\begin{itemize}
    \item Generate matrix $M_0$ and $PAD_0$ randomly from field $\mathbb{F}$. Then compute $M_0^\prime$ and $PAD_0^\prime$ as follows:
    $$
        M_0^{\prime} = \textbf{Enc}_{1,\cdots,t-1}(M_0) \in \mathbb{F}^{N^{t-1} \cdot m}
    $$
    $$
        PAD_0^{\prime} = \textbf{Enc}_{1,\cdots,t-1}(PAD_0) \in \mathbb{F}^{N^{t-1} \cdot m}
    $$
    \item Then compute $M_i^{\prime}$ and $PAD_i^\prime$ for $i \in [t-1]$:
    $$
        PAD_i = \textbf{Fold}_{t-i+1}(PAD_{i-1}, r_i) \in \mathbb{F}^{m^{t-i}}
    $$
    $$
        M_i = \textbf{Fold}_{t-i+1}(M_{i-1}, r_i) \in \mathbb{F}^{m^{t-i}}
    $$
    $$
        M_i^\prime =  \textbf{Enc}_{1, \cdots, t- i - 1}(M_i) \in \mathbb{F}^{N^{t-i-1} \cdot m}
    $$
    $$
        PAD_i^\prime =  \textbf{Enc}_{1, \cdots, t- i - 1}(PAD_i) \in \mathbb{F}^{N^{t-i-1} \cdot m}
    $$
\end{itemize}

If the verifier query $M_i^{\prime}$ or $PAD_i^\prime$ at index $I = (j_1, j_2, \cdots, j_t)$:

\begin{itemize}
    \item If $j_k \le m$ for $\forall k \in [t]$ (this is the message part),
    
    In the simulation world, both $M_0^\prime[I]$ and $PAD_0^\prime[I]$ are uniformly random variables. And both $M_i^\prime[I]$ and $PAD_i^\prime[I]$ for $i > 0$ are linear combinations of a set of uniformly random variables, which are also uniformly random variables.
    
    In the real world, $PAD_0^\prime[I]$ is a uniformly random variable by definition. $M_0^\prime[I]$ is also a uniformly random variable because $M_0^\prime[I] = u[I] + PAD_0^\prime[I]$. Similarly, both $M_i^\prime[I]$ and $PAD_i^\prime[I]$ for $i > 0$ are linear combinations of a set of uniformly random variables, which are also uniformly random variables.
    
    Therefore, the verifier will see a uniformly distributed random element from $\mathbb{F}$ both in the simulation world and in the real world.
    
    \item Otherwise,
    
    In the simulation world and in the real world, $M_i^\prime[I]$ can be determined by a set of random elements in $M_i$. Denote this computation equation as $\textsc{Func}$, namely, $M_i^\prime[I] = \textsc{Func}(M_i[I_1], \cdots, M_i[I_x])$. And $M_i^\prime[I]$ will represent a distribution that is uniquely determined by function \textsc{Func} and the distribution of variables $M_i[I_1], \cdots, M_i[I_x]$. Similarly, $PAD_i^\prime[I]$ will represent a distribution that is uniquely determined by function \textsc{Func} and the distribution of variables $PAD_i[I_1], \cdots, PAD_i[I_x]$.
    
    Note that both in the simulation world and in the real world, $M_i[I_1], \cdots, M_i[I_x]$ and $PAD_i[I_1], \cdots, PAD_i[I_x]$ will represent uniformly random variables. And since the function \textsc{Func} is identical in both cases, the distribution of $M_i^\prime[I]$ and $PAD_i^\prime[I]$ will be identical in two worlds.
    
    
\end{itemize}

The random variables in $\textbf{S}^{\textbf{V}(\mathbb{X};\rho)}(\mathbb{X})$ and in $\text{View}(\textbf{P}(\mathbb{X}, \mathbb{W}), \textbf{V}(\mathbb{X};\rho))$ are indistinguishable to each other. They are identically distributed.

Note that although $PAD_i$ and $M_i$ are correlated (the subtraction of them is the underlying polynomial coefficients), the verifier $\mathcal{V}$ will not be able to observe this correlation because the verifier is not allowed to query both $PAD_i$ and $M_i$ at the same index. The verifier is only allowed to query one of them.

\end{proof}
However, there is one missing problem in lemma \ref{lemma:szkpc-zk}. In the polynomial commitment protocol, the adversary can learn up to $\lambda$ entries of a codeword.
The lemma does not mention whether it is possible for the adversary to infer another entry given these $\lambda$ entries, and then to distinguish the transcripts based on this inferred information. We can construct a counterexample to break it using the following codeword.

\begin{definition}[times-2 linear code $\mathcal{C}_{\times 2}$]
% \label{def:szkpc-times2-lc}
 Given a linear code $\mathcal{C}$ and its encoding function \textsc{Enc}, the encoding function $\textsc{Enc}_{\times 2}$ of the times-2 linear code $\mathcal{C}_{\times 2}$ is defined as follows:
 $$
    \textsc{Enc}_{\times 2} (m) = (\textsc{Enc}(m), \textsc{Enc}(m))
 $$
\end{definition}



\begin{lemma}
\label{lemma:szkpc-zk-cexample}

IOPP = ($\textbf{P}$, $\textbf{V}$) is NOT \textbf{semi-honest zero-knowledge}.

\end{lemma}
\begin{proof}

Without loss of generality, we assume the dimension $t$ is 3. This counterexample can be extended to higher dimension situations naturally. Given a linear code $\mathcal{C}$ from $\mathbb{F}^m$ to $\mathbb{F}^N$. We construct the times-2 linear code $\mathcal{C}_{\times 2}$, whose encoding function \textsc{Enc} maps messages from $\mathbb{F}^m$ to $\mathbb{F}^{2N}$.

In the query phase, the verifier can manipulate the randomness appropriately such that the verifier $\mathcal{V}$ can query $M_0^\prime$ at position $(0, 0, 0)$ and $PAD_0^\prime$ at position $(0, N, 0)$.
Because the construction of $\mathcal{C}_{\times 2}$, elements at position $(0, N, 0)$ will be identical to elements at position $(0, 0, 0)$. 
Therefore, the polynomial coefficient at position $(0, 0, 0)$ is $M_0^\prime[0, 0, 0] - PAD_0^\prime[0, 0, 0] = M_0^\prime[0, 0, 0] - PAD_0^\prime[0, N, 0]$.
\end{proof}









To fix this problem, we need to use the following definition.

\begin{definition}[$l$-query independent codeword]
\label{def:l-ind-codeword}
A linear code $\mathcal{C}$ is $l$-query independent if all adversaries $\mathcal{A}$ cannot distinguish a random value from an entry in the codeword when the adversary $\mathcal{A}$ can make $l$ queries to the codeword. And the adversary $\mathcal{A}$ can choose the challenge position $I^\prime$ himself. Formally speaking, the following probability should be negligible:


$$
\left \lvert
Pr
\begin{pmatrix}
 b = b^\prime : \\
 c \overset{{\scriptscriptstyle\$}}{\leftarrow} \mathcal{C} \\
 b \overset{{\scriptscriptstyle\$}}{\leftarrow} \{0, 1\} \\
 t_0 \overset{{\scriptscriptstyle\$}}{\leftarrow} \mathbb{F} \\
 (I_1, \cdots, I_l) \leftarrow \mathcal{A} \\
 \mathcal{A} \leftarrow c[I_1], \cdots, c[I_l] \\
 I^\prime \leftarrow \mathcal{A} \\
 t_1 \leftarrow c[I^\prime] \\
 b^\prime \leftarrow \mathcal{A}(t_b, \mathcal{C})
\end{pmatrix}
- \frac{1}{2}
\right \rvert
$$
\end{definition}

We sample a random codeword in this definition, which is a little bit different from \cite{BCL22}, because in the context we are using this definition the codewords are random. We include randomness to reflect this situation.

\begin{lemma}
\label{lemma:lquery-zk}

A linear code $\mathcal{C}$ is $l$-query independent if and only if any $l+1$ columns of the generator matrix $G$ are linearly independent of each other.

\end{lemma}

\begin{proof}
First, we prove the ``only if'' part, i.e. a linear code $\mathcal{C}$ is $l$-query independent $\Rightarrow$ any $l+1$ columns of the generator matrix $G$ are linearly independent of each other.

We prove it by contrapositive. Suppose there exists $l+1$ columns of generator matrix $G$ that are NOT linearly independent of each other. We use $G[I_1], \cdots, G[I_l]$ and $G[I_{l+1}]$ to denote these $l+1$ columns. Without loss of generality, it must be possible to write $G[I_{l+1}]$ as a linear combination of $G[I_1], \cdots, G[I_l]$. Namely, 
$$
    G[I_{l+1}] = a_{1}G[I_1] + \cdots + a_{l}G[I_l]
$$
Then, in the game defined in definition \ref{def:l-ind-codeword}, the adversary $\mathcal{A}$ will query indices $I_1, \cdots, I_l$ and learn $c[I_1], \cdots, c[I_l]$. Also, the adversary $\mathcal{A}$ will choose $I_{l+1}$ as the challenge and compute $c[I_{l+1}]$ using the following equation,
\begin{align}
c[I_{l+1}] 
    &= G[I_{l+1}] \cdot m  
    && \cdot \text{ represents dot product} \nonumber \\
    &= (a_{1}G[I_1] + \cdots + a_{l}G[I_l]) \cdot m 
    &&  m \text{ is the message} \nonumber \\
    &= a_{1}(G[I_1]\cdot m) + \cdots + a_{l}(G[I_l]\cdot m) \nonumber \\
    &= a_1 c[I_1] + \cdots + a_{l} c[I_l] \nonumber
\end{align}
At the end, the adversary $\mathcal{A}$ will output 1 if $t_b = c[I_{l+1}]$. Otherwise, the adversary $\mathcal{A}$ will output 0. 

If $b = 1$, then the adversary $\mathcal{A}$ always wins the game. 

If $b=0$, then the adversary $\mathcal{A}$ wins when $t_0 \neq c[I_{l+1}]$. Since $t_0$ is sampled uniformly, the adversary $\mathcal{A}$ wins with probability $1 - \frac{1}{q}$, where $q$ is the size of the field $\mathbb{F}$. 

Hence, the adversary $\mathcal{A}$'s advantage is $\frac{1}{2} + \frac{1}{2}(1 - \frac{1}{q})$ and this linear code $\mathcal{C}$ is NOT $l$-query independent.

Second, we prove the ``if'' part, i.e. any $l+1$ columns of the generator matrix $G$ are linearly independent of each other $\Rightarrow$ a linear code $\mathcal{C}$ is $l$-query independent.

Without loss of generality, the adversary $\mathcal{A}$ will query indices $I_1, \cdots, I_l$ and learn $c[I_1], \cdots, c[I_l]$ in the game defined in definition \ref{def:l-ind-codeword}. Also, the adversary $\mathcal{A}$ will choose $I_{l+1}$ as the challenge. we use $G[I_1], \cdots, G[I_l]$ and $G[I_{l+1}]$ to denote these $l+1$ columns in the generator matrix $G$. Then we create the following $(l+1)\times(k+1)$ matrix $H$,
$$
H = 
\begin{bmatrix}
    G[I_1]^T & c[I_1] \\
    \vdots & \vdots \\
    G[I_{l}]^T & c[I_{l}] \\
    G[I_{l+1}]^T & c[I_{l+1}]
\end{bmatrix}  
$$
In $H$, only $c[I_{l+1}]$ is unknown. And we refer to the last row as the challenge row. Then we run the Gaussian elimination algorithm on it and get the $H^\prime$ matrix in reduced row echelon form. Because these $l+1$ columns are linearly independent of each other, each row in the $H^\prime$ matrix will have a pivot element. We use $j$ to denote the pivot position of the challenge row. And the challenge row should have the following form,
$$
H^\prime_{\text{challenge}} = 
\begin{bmatrix}
    0 & \dots & 0 & 1 &  & \dots &  & c[I_{l+1}] + s
\end{bmatrix}  
$$
where $s$ is a known value and is introduced by those row operations in the Gaussian elimination algorithm.

And it is equivalent to the following equation,
\begin{equation}
\label{eq:lind-gau}
    m_j + \sum_{a=j+1}^{k} m_a H^\prime_{\text{challenge}}[a] = c[I_{l+1}] + s
\end{equation}
where $m_a$ is the $a$-th element in the message $m$.

By rearranging the equation \ref{eq:lind-gau}, we have the following equation,
\begin{equation}
    c[I_{l+1}] = m_j + s^\prime
\end{equation}
where $s^\prime = \sum_{a=j+1}^{k} m_a H^\prime_{\text{challenge}}[a] - s$. 

By definition of the reduced row echelon form, the $j$-th column of matrix $H^\prime$ are all zeros except the one in the challenge row. This implies that $m_j$ is not computable from $c[I_1], \cdots, c[I_l]$. Since the codeword is sampled uniformly random, $m_j$ looks random. And $c[I_{l+1}]$ is also uniformly random from the adversary $\mathcal{A}$'s perspective. Therefore, the adversary $\mathcal{A}$ cannot distinguish it from a random element $t_0$ and win the game. 

\qedsymbol{}
$ $
\end{proof}

\begin{lemma}
\label{lemma:szkpc-zk-final}

IOPP = ($\textbf{P}$, $\textbf{V}$) is \textbf{semi-honest zero-knowledge} if IOPP is ``almost'' semi-honest zero-knowledge according to lemma \ref{lemma:szkpc-zk}, the codeword used in IOPP is $l$-query independent, and $\lambda \le l$.

\end{lemma}
\begin{proof}

According to lemma \ref{lemma:szkpc-zk}, the transcript generated by the simulator is indistinguishable from a real-world transcript. And since the codeword used in IOPP is $l$-query independent and $\lambda \le l$, the adversary is not able to infer more information from that. Hence, the protocol leaks no information.

\qedsymbol{}
$ $
\end{proof}

The only remaining problem is how to prove a linear code is $l$-query independent. Depending on the structure of the specific linear code, one may construct a proof easily. For example, the following lemma shows Reed-Solomon code ($\mathbb{F}^k \rightarrow \mathbb{F}^n$) is $k$-query independent.

\begin{lemma}
\label{lemma:rscode-kzk}

A Reed-Solomon code that maps from $\mathbb{F}^k$ to $\mathbb{F}^n$ is $k$-query independent.

\end{lemma}
\begin{proof}

The codeword of the Reed-Solomon code is in the following format:
$$
\mathcal{C}(x) = 
(
p_x(a_1), p_x(a_2), \cdots, p_x(a_n)
)
$$
$$
p_x(a) = \sum_{i=1}^k x_i a^{i-1}
$$
where $x$ is the input message, $p$ is a polynomial of degree $k$, and $a_1, a_2, \cdots, a_n$ are some coefficients.
It is clear that $k+1$ evaluation points are required to fix a polynomial with degree $k$. If only $k$ evaluation points are provided, then no information is leaking.
\qedsymbol{}
\end{proof}

For a general codeword, one may use the lemma \ref{lemma:lquery-zk} to test the code naively in a brute-force manner. Faster algorithms are possible with the help of the minimum distance decoding algorithm. However, whether it is possible to find an efficient algorithm remains an open question.