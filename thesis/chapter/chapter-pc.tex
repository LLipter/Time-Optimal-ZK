\chapter{IOPs for Polynomial Commitment}

In this chapter, we present a general polynomial commitment scheme in the language of IOP for arbitrary dimension $t$. The scheme is an extension of the polynomial commitment scheme for $t=2$ described in \cite{brakedown}, which is also described in \cite{cryptoeprint:2020/1426}. We first present the formal description of the protocol. Then we generalize it to arbitrary $t$ with detailed analysis available.

\section{Notation}

Let $g$ be a multilinear polynomial with $n$ coefficients. For simplicity, we assume that $n = m^t$ for some integer $m$. And let $u$ denote the coefficient vector of $g$ in the Lagrange basis, which means $u$ represents all evaluations of $g$ over inputs in hypercube $\{0, 1\}^{\log n}$. 
We can rearrange $u$ to be a $\underbrace{n^{\frac{1}{t}} \times n^{\frac{1}{t}} \times \cdots \times n^{\frac{1}{t}}}_{t \text{ times}}$ matrix, such that we can index entries in this matrix easily by elements from set $[m]^t$.

Let $N = \rho^{-1} \cdot m$ and \text{Enc}: $\mathbb{F}^m \rightarrow \mathbb{F}^N$ represent the encoding function of a linear code with a constant rate $\rho > 0$ and a constant minimum relative distance $\gamma > 0$.

\subsubsection{Encode Operation}

Let $\text{Enc}_i(M)$ denote the function that encodes every stripe in the $i$-th dimension of the matrix $M$ using encoding function Enc. For example, $\text{Enc}_1(M)$ will encode each column of a $n \times n $ matrix and produce a $N \times m$ matrix.


Define $\textbf{Enc}_{1,\cdots,i}$ be short-hand for $\text{Enc}_1 \circ \text{Enc}_2 \circ \cdots \circ \text{Enc}_{i}$.

\subsubsection{Fold Operation}

Define $\textbf{Fold}_i(X, r)$ to be the operation taking a linear combination of $X$ across the $i$-th dimension according to coefficient $r$. 

Namely, for indexes $j_1, \cdots, j_{i-1}, j_{i+1}, \cdots , j_{k} \ge 1$:
$$
\textbf{Fold}_i(X, r)[j_1, \cdots, j_{i-1}, j_{i+1}, \cdots , j_{k}] = \sum_{k=1}^{m} r_{i}[k] \cdot X[j_1, \cdots, j_{i-1}, k, j_{i+1}, \cdots , j_{k}]
$$



Since the IOPs in this section work for general tensor products, we also need to express the polynomial evaluation as a tensor product.

\begin{lemma}[Polynomial Evaluation \cite{brakedown}]
\label{lemma:petq}

For an $l$-variate multilinear polynomial $g$ represented in the Lagrange basis via a vector $u \in \mathbb{F}^{n}$ where $2^l = n$, given an evaluation point $x \in \mathbb{F}^l$, $g(x)$ can be evaluated using the following tensor product identity: 

\[
    g(x) = \langle (x_1, 1-x_1) \otimes (x_2, 1-x_2) \otimes \cdots \otimes (x_l, 1-x_l) , u \rangle
\]

And for any $ 1 \le t  \le l$ (we assume $t|l$ for simplicity), there always exist vectors $q_1, q_2, \cdots , q_t \in \mathbb{F}^{n^{\frac{1}{t}}}$ such that the following holds:

\[
    (x_1, 1-x_1) \otimes (x_2, 1-x_2) \otimes \cdots \otimes (x_l, 1-x_l) = q_1 \otimes q_2 \otimes \cdots \otimes q_t
\]

\end{lemma}


\section{Proximity Test for Arbitrary t}

The proximity test is the core component of the polynomial commitment scheme, which will test whether $(\mathbb{X}, \mathbb{W})$ is in relation $R_\otimes^1$ (definition \ref{def:relation-prox}). The purpose of this protocol is to convince the verifier $\mathcal{V}$ that a matrix $M$ is very close to a valid tensor code $C^{\otimes t}$.

\subsection{Formal Description}

Prover $\mathcal{P}$'s input: 
$$
    M_0 \in \mathbb{F}^{\overbrace{m \times m \times \cdots \times m}^{t \text{ times}}}
$$
$$
    M_0^{\prime} = \textbf{Enc}_{1,\cdots,t-1}(M_0) \in \mathbb{F}^{\overbrace{N \times N \times \cdots \times N}^{t-1 \text{ times}} \times m}
$$

Verifier $\mathcal{V}$'s input: nothing.

At a high level, the protocol consists of $t-1$ rounds, with each round reducing the dimension by 1. The protocol proceeds as follows. 

\begin{itemize}
    \item $\mathcal{P}$ sends $M_0^{\prime}$ to $\mathcal{V}$.
    
    \item Round $i$ for $i \in [t-1]$
    
    \begin{itemize}
        \item $\mathcal{V}$ sample a random variable $r_i \in \mathbb{F}^m$ and send $r_i$ to $\mathcal{P}$.
        \item $\mathcal{P}$ computes a linear combination 
        $M_i \in \mathbb{F}^{\overbrace{N \times N \times \cdots \times N}^{t-1 \text{ times}} \times m}$ of the last dimension of matrix $M_{i-1}$.
        Namely,
$$
    M_i = \textbf{Fold}_{t-i+1}(M_{i-1}, r_i)
$$

        \item $\mathcal{P}$ computes 
$$
    M_i^\prime =  \textbf{Enc}_{1,\cdots,t-i-1}(M_i)\in \mathbb{F}^{\overbrace{N \times N \times \cdots \times N}^{t-i-1 \text{ times}} \times m}
$$    
        and sends $M_i^\prime$ to $\mathcal{V}$.
    \end{itemize}
    
    \item $\mathcal{V}$ performs a probabilistic check to make sure $M_0^\prime$, $M_1^\prime$, $M_2^\prime, \cdots, M_{t-1}^\prime$ are consistent with each other. Formally speaking, $\mathcal{V}$ will sample $l$ random tuple $(j_1, j_2, \cdots, j_t)$ from space $\overbrace{[N] \times [N] \times \cdots \times [N]}^{t \text{ times}}$. 
    For each tuple $(j_1, j_2, \cdots, j_t)$, 
    $\mathcal{V}$ will check whether the following equation holds for every $i \in [t-1]$:
$$
    \text{Enc}(M_i^\prime[j_1, j_2, \cdots, j_{t-i-1}, *])[j_{t-i}] \stackrel{?}{=} \sum_{k=1}^m r_i[k] \cdot M_{i-1}^{\prime}[j_1,j_2, \cdots, j_{t-i},k]
$$
\end{itemize}

\section{Consistency Test}

Let $q_1, q_2, \cdots, q_t \in \mathbb{F}^{m}$ be vectors such that $g(x) =\langle q_1 \otimes q_2 \otimes \cdots \otimes q_t, u \rangle $. The consistency test is identical to the proximity test, except that in round $i$, the random linear combination $r_i$ is replaced by $q_i$. It will test whether $(\mathbb{X}, \mathbb{W})$ is in relation $R_{cons}^1$ (definition \ref{def:relation-cons}). The full description of the consistency test is written below.

\subsection{Formal Description}

Prover $\mathcal{P}$'s input: 
$$
    M_0 \in \mathbb{F}^{\overbrace{m \times m \times \cdots \times m}^{t \text{ times}}}
$$
$$
    M_0^{\prime} = \textbf{Enc}_{1,\cdots,t-1}(M_0) \in \mathbb{F}^{\overbrace{N \times N \times \cdots \times N}^{t-1 \text{ times}} \times m}
$$

Verifier $\mathcal{V}$'s input: $q_1, q_2, \cdots, q_t \in \mathbb{F}^{m}$ such that $g(x) =\langle q_1 \otimes q_2 \otimes \cdots \otimes q_t, u \rangle$.

At a high level, the protocol consists of $t-1$ rounds, with each round reducing the dimension by 1. The protocol proceeds as follows. 

\begin{itemize}
    \item $\mathcal{P}$ sends $M_0^{\prime}$ to $\mathcal{V}$.
    
    \item Round $i$ for $i \in [t-1]$
    
    \begin{itemize}
        \item $\mathcal{V}$ send $q_i$ to $\mathcal{P}$.
        \item $\mathcal{P}$ computes a linear combination 
        $M_i \in \mathbb{F}^{\overbrace{N \times N \times \cdots \times N}^{t-1 \text{ times}} \times m}$ of the last dimension of matrix $M_{i-1}$. Namely,
$$
    M_i = \textbf{Fold}_{t-i+1}(M_{i-1}, q_i)
$$

        \item $\mathcal{P}$ computes 
$$
    M_i^\prime =  \textbf{Enc}_{1,\cdots,t-i-1}(M_i)\in \mathbb{F}^{\overbrace{N \times N \times \cdots \times N}^{t-i-1 \text{ times}} \times m}
$$    
        and sends $M_i^\prime$ to $\mathcal{V}$.
    \end{itemize}
    
    \item $\mathcal{V}$ performs a probabilistic check to make sure $M_0^\prime$, $M_1^\prime$, $M_2^\prime, \cdots, M_{t-1}^\prime$ are consistent with each other. Formally speaking, $\mathcal{V}$ will sample $l$ random tuple $(j_1, j_2, \cdots, j_t)$ from space $\overbrace{[N] \times [N] \times \cdots \times [N]}^{t \text{ times}}$. 
    For each tuple $(j_1, j_2, \cdots, j_t)$, 
    $\mathcal{V}$ will check whether the following equation holds for every $i \in [t-1]$:
$$
    \text{Enc}(M_i^\prime[j_1, j_2, \cdots, j_{t-i-1}, *])[j_{t-i}] \stackrel{?}{=} \sum_{k=1}^m q_i[k] \cdot M_{i-1}^{\prime}[j_1,j_2, \cdots, j_{t-i},k]
$$
\end{itemize}

\section{Polynomial Commitment for Arbitrary t}

Prover $\mathcal{P}$'s input: $u \in \mathbb{F}^{\overbrace{m \times m \times \cdots \times m}^{t \text{ times}}}$.

Verifier $\mathcal{V}$'s input: $x, y \in \mathbb{F}$.

\subsection{Protocol}

\textbf{Commitment Phase.}

Let $M_0 = u \in \mathbb{F}^{\overbrace{m \times m \times \cdots \times m}^{t \text{ times}}}$ and $ M_0^{\prime} = \text{Enc}_1 \circ \text{Enc}_2 \circ \cdots \circ \text{Enc}_{t-1} (M_0) \in \mathbb{F}^{\overbrace{N \times N \times \cdots \times N}^{t-1 \text{ times}} \times m}$. $\mathcal{P}$ sends $M_0^{\prime}$ to $\mathcal{V}$.

\textbf{Evaluation Phase.}

Execute the consistency test protocol. The prover $\mathcal{P}$'s input is $(M_0, M_0^{\prime})$ and the verifier $\mathcal{V}$'s input is $(q_1, q_2, \cdots, q_t)$ such that $g(x) =\langle q_1 \otimes q_2 \otimes \cdots \otimes q_t, u \rangle $.
If all consistency checks are passed, then the verifier $\mathcal{V}$ will consider $\langle q_t, M_{t-1} \rangle$ as the evaluation result $g(x)$. 

\textbf{Testing Phase.}

For each $0 \le i \le t-1$, execute the proximity test protocol. The prover $\mathcal{P}$'s input is $(M_i, M_i^{\prime})$.

If all tests passed, the verifier $\mathcal{V}$ will output the evaluation result. Otherwise, the verifier $\mathcal{V}$ will reject the protocol.

\section{Analysis}

We refer to the result in \cite{cryptoeprint:2020/1426} and summarize the following lemmas. 

\begin{lemma}
\label{lemma:pc-completeness}
The testing phase (proximity test) has perfect completeness.
\end{lemma}

\begin{lemma}
\label{lemma:pc-soundness}
The testing phase (proximity test) has soundness error:
$$
    \epsilon(\Delta_\otimes, t, l) = \frac{d(d^t-1)}{4(d-1)|\mathbb{F}|} + (1 - \text{ min}\{\frac{\delta^t}{4}, \Delta_\otimes \})^l
$$
where $d = \delta \cdot N$, and $\delta$ denotes the relative distance.
\end{lemma}


\section{Implementation Details}

The protocol presented above is in the IOP model and is not concrete polynomial commitment algorithms. We can use the Merkle tree to compile such point-query IOPs into concrete arguments.

\subsection{Merkle Tree Commitment}

A Merkle Tree is a data structure that allows one to commit to $l = 2^{d}$ messages by a single hash value $h$, such that revealing any bit of the message requires $d+1$ hash values. A Merkle hash tree is presented by a binary tree of depth $d$ where $l$ messages elements $m_1, m_2, \cdots, m_l$ are assigned to the leaves of the tree. The values assigned to internal nodes are computed by hashing the value of its two child nodes. To reveal $m_i$, we need to reveal $m_i$ together with the values on the path from $m_i$ to the root. We denote the algorithm as follows:

\begin{enumerate}
    \item $h \leftarrow \textsc{Merkle.Commit}(m_1, m_2, \cdots, m_l)$
    \item $(m_i, \phi_i) \leftarrow \textsc{Merkle.Open}(m, i)$
    \item $\{\textsc{accept}, \textsc{reject}\} \leftarrow \textsc{Merkle.Verify}(\phi_i, m_i, h)$
\end{enumerate}

In practice, we use Merkle tree commitment to compile the IOP or IOPP to a real argument system. Each element in the large array message $\pi$ sent by the prover will be considered to be a leaf node of a Merkle tree. And the corresponding Merkle tree root will be sent to the verifier instead. For each query at position $I$, the prover will respond with $\pi[I]$ and the corresponding Merkle tree path, which will be authenticated later by the verifier.

Coefficient matrices $M_0^\prime, M_1^\prime, \cdots, M_{t-1}^\prime$ sent by the prover may be replaced by a Merkle tree commitment to that matrix. And since each time the verifier will query a strip of elements in a matrix (i.e. $M_i^\prime[i_1, i_2, \cdots, i_{t-i-1}, *]$), it is possible to zip such a strip of elements into a single node in Merkle-tree's leaf level to decrease runtime complexity and communication complexity.

\subsection{Zero-knowledge Merkle Tree Commitment}

To implement a zero-knowledge polynomial commitment scheme, we also need a zero-knowledge Merkle tree commitment to prevent information-leaking from the Merkle tree path. If we use the random oracle model, we can argue that the Merkle hash is completely random, thus, leaking no information at all. On the other hand, we can prevent information leaking by adding randomness to the leaf nodes. The leaf node is $hash(data_i || r_i)$ where $r_i$ is some random elements. 

\subsection{Parallelism}

Most of the computations for the polynomial commitment scheme can be done in parallel in a natural fashion. There is little data dependence among them. Therefore, it is possible to run the commitment scheme using multiple threads to increase efficiency significantly for both the prover and the verifier.



\section{Benchmark}

\subsection{Runtime}


\begin{table}[h!]
\centering
\begin{tabular}{| c | m{4em}  | m{3em}  | m{3.5em} | m{2.5em} | m{5em} | m{7em} |} 
 \hline
 Dimension & Message Length $m$ & Code Length $N$ & Commit Time [ms] & Verify Time [ms] & Soundness Error & Communication Complexity [Field Element] \\ [0.5ex] 
 \hline\hline
 2 & 1024   & 1762 & 41737  & 3057  & 0.37 & 1206579 \\
 \hline
 3 & 101    & 174 & 99642  & 623  & 1.76 & 235621  \\
 \hline
 4 & 32     & 56 & 153558  & 204  & 1.98 & 114701   \\
 \hline
\end{tabular}
\caption{Runtime of polynomial commitment scheme with $2^{20}$ coefficients, 1 thread, linear code with relative distance 0.07, and 1000 test tuples.}
\label{table:benchmark-pc-1}
\end{table}


We benchmark the above polynomial commitment scheme on a computer with
Intel \textregistered \, Core  \textsuperscript{TM} i7-7700HQ CPU @ 2.80GHz (Kabylake), L1 cache: 128KB, L2 cache: 256KB and L3 cache: 6MB. There are 8 physical CPU cores available on this machine. We use the Brakedown linear code presented in \cite{brakedown}. The runtimes are summarized in the table \ref{table:benchmark-pc-1} and table \ref{table:benchmark-pc-2}.


Running the polynomial commitment scheme with the same setting, using 8-threads-parallelism can provide approximately a 4x speedup.

\begin{table}[h!]
\centering
\begin{tabular}{| c | m{4em}  | m{3em}  | m{3.5em} | m{2.5em} | m{5em} | m{7em} |} 
 \hline
 Dimension & Message Length $m$ & Code Length $n$ & Commit Time [ms] & Verify Time [ms] & Soundness Error & Communication Complexity [Field Element] \\ [0.5ex] 
 \hline\hline
 2 & 1024   & 1762 & 10048 & 776 & 0.37 & 1206579  \\
 \hline
 3 & 101    & 174 & 24314 & 165 & 1.76 & 235621 \\
 \hline
 4 & 32     & 56 & 37961 & 63 & 1.98 & 114701  \\ 
 \hline
\end{tabular}
\caption{Runtime of polynomial commitment scheme with $2^{20}$ coefficients, 8 threads, linear code with relative distance 0.07, and 1000 test tuples.}
\label{table:benchmark-pc-2}
\end{table}


As the dimension increases, it generally requires more time to complete the commit phase for the prover. And less time is required to complete the verification phase for the verifier. Also, a high-dimensional polynomial commitment scheme will have less communication complexity. However, since the relative distance is decreasing as the tensor code's dimension is increasing, the soundness error will also increase. In fact, the soundness error for 3-dimensional and 4-dimensional polynomial commitment schemes is higher than 1, which is unusable in practice.

\subsection{Soundness Error}

According to lemma \ref{lemma:pc-soundness}, we can compute the soundness error summarized in the table \ref{table:benchmark-pc-3}.

\begin{table}[h!]
\centering
\begin{tabular}{| c | m{5em} | m{5em} | m{5em}  | m{5em}|} 
 \hline
 Dimension & Number of Test Tuples & Code Length & Code Relative Distance & Soundness Error \\ [0.5ex] 
 \hline\hline
 
 \multirow{3}{*}{2} & 100 & 1762 & 0.07 & 1.66  \\
  & 1000 & 1762 & 0.07 & 0.37  \\
  & 100 & 1762 & 0.55* & 0.0003  \\
 \hline
 
 \multirow{3}{*}{3} & 100 & 174  & 0.07 & 1.97 \\
 & 1000 & 174  & 0.07 & 1.76 \\
 & 100 & 174  & 0.55* & 0.01 \\
 \hline
 
 \multirow{3}{*}{4} & 100 & 56   & 0.07 & 1.99  \\
  & 1000 & 56   & 0.07 & 1.98  \\
  & 100 & 56   & 0.55* & 0.10  \\ 
 \hline
\end{tabular}
\caption{Soundness error of polynomial commitment scheme. (* represents an imaginary linear code with a relative distance of 0.55)}
\label{table:benchmark-pc-3}
\end{table}

The theoretically computed soundness error for the setting used in the above benchmark experiment is large, even above 1, making it not usable in practice. The soundness error can be decreased by either increasing the number of tested tuples or by increasing the relative distance of the underlying linear code. However, the soundness error is not sensitive to the number of tested tuples and the length of the code is usually quite limited. Therefore, using a linear code with a large relative distance is the only promising solution here. One of our conclusion would be high dimension polynomial commitment scheme is not worth using unless we can improve the relative distance of these linear codes used in the constructions significantly. However, improving relative distance seems to be a difficult task.